{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumPy and Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While base Python has many useful tools for a wide-variety purposes, open-source external libraries greatly expand Python's uses. Here, we will discuss two of the most popular libraries: **NumPy** and **Pandas**. Both of these are invaluable to data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy (Numerical Python) is a critical library for manipulating numbers, performing matrix operations, and mathematics in general. \n",
    "\n",
    "To use this library, we first have to **import** it with the keyword `import`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have access to the various tools and functions that NumPy has to offer. The foundation of NumPy is the array, a data structure for holding numbers designed for math. \n",
    "\n",
    "The simplest array is a single dimensional vector, essentially a Python list that we can do math with. To make an array, we tend to create a list and convert it to an array with `numpy.array()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can always do simple math operations between a number (int or float) and an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have arrays of the same length, we can do the same operations on them between elements in the same positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use numpy functions like `add()` and `multiply()` to do these actions, as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus\n",
    "It is common practice in Python to use `import numpy as np` when importing NumPy. This allows you to only need to type `np.` (e.g., `np.add()`) when using a tool within NumPy, which is a bit less clunky and faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could technically import NumPy as any variable name, but **DO NOT DO THIS** to avoid confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question: NumPy math\n",
    "\n",
    "Create two NumPy arrays of the same length and subtract one from the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Array\n",
    "\n",
    "NumPy arrays really come into their own when they're used as matrices. Let's first make a 3 x 3 array. To do this, we will call `numpy.array()` with a list that contains other lists, also called a **nested list**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the dimensions of the array by checking the `.shape` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like the single dimensional array, you can use the standard math operators between 2D arrays, though they have to be of the same shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like a 1D vector, you can also do math operations with a single number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy comes with many tools to do various more complicated math operations as well. For instance, `numpy.matmul` can be used for matrix multiplication. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is non-exhaustive list of other useful operations you can calculate with NumPy. Many of them use the submodule `linalg` that specializes in linear algebra operations.\n",
    "- Natural logarithm: `numpy.log()`\n",
    "- Base 10 log: `numpy.log10()`\n",
    "- Exponential ($e^x$): `numpy.exp()`\n",
    "- Mean: `numpy.mean()`\n",
    "- Median: `numpy.median()`\n",
    "- Maximum: `numpy.max()`\n",
    "- Minimum: `numpy.min()`\n",
    "- Standard deviation: `numpy.std()`\n",
    "- Variance: `numpy.var()`\n",
    "- Dot product: `numpy.dot()`\n",
    "- Determinant: `numpy.linalg.det()`\n",
    "- Vector/matrix norm: `numpy.linalg.norm()`\n",
    "- Matrix rank: `numpy.linalg.det()`\n",
    "- Matrix inverse: `numpy.linalg.inv()`\n",
    "- Eigenvalues/eigenvectors: `numpy.linalg.eig()`\n",
    "- Solutions to linear equations: `numpy.linalg.solve()`\n",
    "\n",
    "For full usage of these functions and more, please visit the [NumPy reference manual](https://numpy.org/doc/stable/reference/routines.linalg.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question: NumPy operations\n",
    "\n",
    "Create a 1D array called `a` with at least 5 values. Find its mean, median, min, max, and standard deviation.\n",
    "\n",
    "Create another 1D array called `b` with the same length as `a`. Use `numpy.dot(a,b)` to find the dot product of `a` and `b`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing and slicing in NumPy\n",
    "\n",
    "Selecting a value in a 1D array is just like indexing in a Python list. If the array has a length of 4, indexes begin at 0 and end at 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2D arrays can be indexed in a similar manner with separate column index and row index -> array[row, col]. Both column and row numbers begin with 0.\n",
    "\n",
    "![array indexing](https://swcarpentry.github.io/python-novice-inflammation/fig/python-zero-index.svg)\n",
    "*Credit to [Software Carpentry](https://swcarpentry.github.io/python-novice-inflammation/02-numpy/index.html)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also like lists, we can use **negative indexing** to get the last values of a column and/or row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also using **slicing** to return portions of an array -> `array[i:j]`. Slicing is **inclusive** for the first index (`i`) and **exclusive** for the last index (`j`). `array[i:j]` returns values from `i` to `j-1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this for 2D arrays, as well. We can slice rows, columns, or both at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question: Slicing\n",
    "\n",
    "What happens when you slice but do not include the first index (`i`), the last index (`j`), or include neither?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### try it out:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy constants\n",
    "\n",
    "Math has many constants and important terms that are not present in vanilla Python. Here is a short list of some important ones:\n",
    "\n",
    "- Positive infinity ($+\\infty$): `numpy.Inf` or `numpy.inf` or `numpy.Infinity` or `numpy.PINF` or `numpy.infty`\n",
    "- Negative infinity ($\\infty$): `numpy.NINF`\n",
    "- Euler's constant $e$: `numpy.e`\n",
    "- Missing values/ Not a Number (NaN): `np.nan` or `np.NaN` or `np.NAN`\n",
    "- pi ($\\pi$): `np.pi`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question: Math\n",
    "\n",
    "Calculate the difference between $+\\infty$ and $\\pi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "While NumPy can be used to important data, it is optimized around numerical data. Many data sets include categorical variables. For these data sets, it is best to use a library called `pandas`, which focuses on creating and manipulating data frames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data\n",
    "With `pandas` imported, we can read in .csv files with the `pandas` function `read_csv()`.\n",
    "\n",
    "In that function, we can specify the file we want to use with a URL or with the path to a local file as a string.\n",
    "\n",
    "This saves the data in a structure called a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/DeisData/python/master/data/gapminder.csv\") # read in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is now saved as a data frame in Python as the variable `df`. With the data now in the environment, we can take a look at the first few rows with `df.head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this data frame has several different columns, with information about countries and demography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize data frame\n",
    "\n",
    "It is important to understand the data we are working with before we begin analysis. First, let's look at the dimenions of the data frame using `df.shape`. It gives the number of rows by the number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that our data frame has 14740 rows by 9 columns.\n",
    "\n",
    "We can also use `df.columns` to display the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical variables\n",
    "Next, let's summarize the categorical, non-numerical variables. For instance, we can identify how many unique regions we have in the data set.\n",
    "\n",
    "First, to select a column, we use the notation `df['COLUMN_NAME']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To identify unique entries in this column, we can use the `pd.unique()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `countries` column has many unique values, so we'll just use the `len()` function to see how many unique countries we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical columns can be summarized in several ways. Let's find the mean first.\n",
    "\n",
    "To make things simpler, we'll just do calculations on the `population`, `life_expectancy`, and `babies_per_woman` columns. We can put those names in a `list` and then specify that list for the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this set of columns, we can run `.mean()` to find the mean of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want a larger variety of summary statistics, we can use the `.describe()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also break down subgroupings of our data with the method `.groupby()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing rows and specific entries\n",
    "\n",
    "You can also to access a specific row using `df.loc[ROW, :]`. The colon specifies to select all columns for that row number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `.loc` to find the value of specific entries, as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question\n",
    "Print out the summary statistics for columns `age5_surviving`, `gdp_per_day`, and `gdp_per_capita`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your code below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulate data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset by row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, we want to create a subset of the main data frame based on certain conditions. We do this by using `df.loc` and specifying a condition for the rows. \n",
    "\n",
    "Below, we take all of the rows where `babies_per_woman` is greater or equal to 4 with `df['babies_per_woman'] >= 4` and assign this to a new data frame.\n",
    "\n",
    "To check that this was done correctly, we can look at the minimum of the `babies_per_woman` column in the new data frame with  `.min()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take all rows where babies_per_woman is greater or equal to 4 and make a new data frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the following operators to make subsets:\n",
    "- Equals: `==`\n",
    "- Not equals: `!=`\n",
    "- Greater than, less than: `>`, `<`\n",
    "- Greater than or equal to: `>=`\n",
    "- Less than or equal to: `<=`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also subset with categorical variables. Here, we take all rows where the country is Hungary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we multiply a data frame by a single number, each value in the column will be muliplied by that value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do math between columns, since they have the same length. Elements of the same row are added, substacted, multiplied, or divided. \n",
    "\n",
    "Here, we subtract the `life_expectancy` column from the `age5_surviving` column and assign it to a new column called `life_difference`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new column is now reflected in the data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question: Working with data \n",
    "\n",
    "Create a subset of data from Lithuania. \n",
    "\n",
    "Within that subset, calculate the mean GDP per 1000 people across entries.\n",
    "\n",
    "*Hint: Multiply per capita GDP by 1000.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create your own data frame\n",
    "\n",
    "To make your own data frame without a .csv, we use the function `pd.DataFrame()`. There are many ways to use this function to construct a data frame. \n",
    "\n",
    "Here, we show how to convert a dictionary of lists into a data frame. Each list will be its own column, and you need to make sure the lists are all the same length. The keys of each list should be the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use lists of lists or 2D NumPy arrays to create data frames. Each list will be a row, instead of a column, and you will need to specify the column name as another argument in `pd.DataFrame()` called `columns`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: we need to save this as a variable to use it in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sort the rows in a data frame by the value of a column, we can use the `.sort_values()` method. The argument `by` requires a list with a column name. \n",
    "\n",
    "Again, if you want to use the sorted version in the future, you need to save it as a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also sort descending by specifying the `ascending=False` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If desired, multiple column names can be specified, with priority given to those first in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add rows\n",
    "There are multiple ways to add a new row to a data frame. The most straightforward way is to use the `pandas.concat()` function with a new data frame with just one row. \n",
    "\n",
    "We put the the two data frames into a list, and we set `axis=0` to make sure it adds as a row. We will specify `.reset_index(drop=True)` to reset row numbers to account for the new row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use this approach to add multiple rows, as well, by having the new data frame consist of multiple rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join data frames\n",
    "A critical tool in data wrangling is combining data frames that share common values, columns, or identifiers.\n",
    "\n",
    "Let's important two new .csv files and join them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_df = pd.read_csv(\"https://raw.githubusercontent.com/DeisData/python/master/data/surveys.csv\", keep_default_na=False, na_values=[\"\"])\n",
    "species_df = pd.read_csv(\"https://raw.githubusercontent.com/DeisData/python/master/data/species.csv\", keep_default_na=False, na_values=[\"\"])\n",
    "\n",
    "print(surveys_df.head())\n",
    "print(species_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shared column between these data frames is `species_id`, so this is the column we will want to join around."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inner Join\n",
    "The pandas function for performing joins is called `merge()` and an Inner join is the default option.\n",
    "\n",
    "Inner joins take all rows from both data frames that share values from an identifier column. In our case, this means that our joined data frame will only include rows with species identifiers present in `species_df` and `surveys_df`.\n",
    "\n",
    "<img src=\"../images/innerjoin.png\" alt=\"inner join\" width=250px>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result `merged_inner` data frame contains all of the columns from `surveys_df` (`record_id`, `month`, `day`, etc.) as well as all the columns from `species_df` (`species_id`, `genus`, `species`, and `taxa`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Left join\n",
    "\n",
    "What if we want to add information from `species_df` to `surveys_df`without losing any of the information from `surveys_df`? In this case, we use a different type of join called a left join, where we keep all rows from the data frame we call left (in our case `surveys_df`) and only take rows from the right data frame (`species_df`) with species IDs in `surveys_df`.\n",
    "\n",
    "<img src=\"../images/leftjoin.png\" alt=\"left join\" width=250px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A left join is performed in pandas by calling the same `merge()` function used for inner join, but using the `how='left'` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export data frame as .csv\n",
    "\n",
    "If you have made modifications to a data set in Python and want to export that to a new .csv, you can easily do that with the `.to_csv()` method that all pandas data frames have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question: Putting it together\n",
    "\n",
    "Create two data frames called `A` and `B` with at least 3 columns and 4 rows. Make one column in both `A` and `B` an identifier column, with at least one ID present in both data frames. Use a left join with `A` as the left data frame, and call the new data frame `C`. Display the data frame, and export it as a .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- [NumPy docs](https://numpy.org/doc/stable/index.html)\n",
    "- [NumPy getting started](https://numpy.org/doc/stable/user/quickstart.html)\n",
    "- [Random samples with NumPy](https://numpy.org/doc/stable/reference/random/index.html)\n",
    "- [Pandas docs](https://pandas.pydata.org/docs/)\n",
    "- [Pandas getting started](https://pandas.pydata.org/docs/getting_started/index.html#getting-started)\n",
    "- [Pandas cheatsheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)\n",
    "- [PySpark for big data](https://spark.apache.org/docs/latest/api/python/)\n",
    "\n",
    "This lesson is adapted from \n",
    "[Software Carpentry](http://swcarpentry.github.io/python-novice-gapminder/design/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('workshop')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e5670abb08844f1af3bbc7bb9ef8e3b4ef400ad7b254432ac9e559b82ca9501"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
