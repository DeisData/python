{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    "While NumPy can be used to important data, it is optimized around numerical data. Many data sets include categorical variables. For these data sets, it is best to use a library called `pandas`, which focuses on creating and manipulating data frames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data\n",
    "With `pandas` imported, we can read in .csv files with the `pandas` function `read_csv()`.\n",
    "\n",
    "In that function, we can specify the file we want to use with a URL or with the path to a local file as a string.\n",
    "\n",
    "This saves the data in a structure called a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/DeisData/python/master/data/gapminder.csv\") # read in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is now saved as a data frame in Python as the variable `df`. With the data now in the environment, we can take a look at the first few rows with `df.head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this data frame has several different columns, with information about countries and demography."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize data frame\n",
    "\n",
    "It is important to understand the data we are working with before we begin analysis. First, let's look at the dimenions of the data frame using `df.shape`. It gives the number of rows by the number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that our data frame has 14740 rows by 9 columns.\n",
    "\n",
    "We can also use `df.columns` to display the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical variables\n",
    "Next, let's summarize the categorical, non-numerical variables. For instance, we can identify how many unique regions we have in the data set.\n",
    "\n",
    "First, to select a column, we use the notation `df['COLUMN_NAME']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `countries` column has many unique values, so instead of `.unique()`, we can use `.nunique()` to find the number of unique countries in the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `countries` column has many unique values, so we'll just use the `len()` function to see how many unique countries we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " # this is called nesting functions -> calling functions within other functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical columns can be summarized in several ways. Let's find the mean first.\n",
    "\n",
    "To make things simpler, we'll just do calculations on the `population`, `life_expectancy`, and `babies_per_woman` columns. We can put those names in a `list` and then specify that list for the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [  ] # numerical columns\n",
    "\n",
    "df[ ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this set of columns, we can run `.mean()` to find the mean of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[num_cols] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want a larger variety of summary statistics, we can use the `.describe()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[num_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also break down subgroupings of our data with the method `.groupby()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing rows and specific entries\n",
    "\n",
    "You can also to access a specific row using `df.loc[ROW, :]`. The colon specifies to select all columns for that row number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `.loc` to find the value of specific entries, as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "Print out the summary statistics for columns `age5_surviving`, `gdp_per_day`, and `gdp_per_capita`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your code below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulate data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset by row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, we want to create a subset of the main data frame based on certain conditions. We do this by using `df.loc` and specifying a condition for the rows. \n",
    "\n",
    "Below, we take all of the rows where `babies_per_woman` is greater or equal to 4 with `df['babies_per_woman'] >= 4` and assign this to a new data frame.\n",
    "\n",
    "To check that this was done correctly, we can look at the minimum of the `babies_per_woman` column in the new data frame with  `.min()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take all rows where babies_per_woman is greater or equal to 4 and make a new data frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the following operators to make subsets:\n",
    "- Equals: `==`\n",
    "- Not equals: `!=`\n",
    "- Greater than, less than: `>`, `<`\n",
    "- Greater than or equal to: `>=`\n",
    "- Less than or equal to: `<=`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also subset with categorical variables. Here, we take all rows where the country is Hungary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we multiply a data frame by a single number, each value in the column will be muliplied by that value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do math between columns, since they have the same length. Elements of the same row are added, substacted, multiplied, or divided. \n",
    "\n",
    "Here, we subtract the `life_expectancy` column from the `age5_surviving` column and assign it to a new column called `life_difference`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new column is now reflected in the data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Working with data \n",
    "\n",
    "Create a subset of data from Lithuania. \n",
    "\n",
    "Within that subset, calculate the mean GDP per 1000 people across entries.\n",
    "\n",
    "*Hint: Multiply per capita GDP by 1000.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create your own data frame\n",
    "\n",
    "To make your own data frame without a .csv, we use the function `pd.DataFrame()`. There are many ways to use this function to construct a data frame. \n",
    "\n",
    "Here, we show how to convert a dictionary of lists into a data frame. Each list will be its own column, and you need to make sure the lists are all the same length. The keys of each list should be the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'a': [1, 3, 5],\n",
    "    'b': ['apple', 'banana', 'apple'],\n",
    "    'c': [-2., -3., -5.]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use lists of lists or 2D NumPy arrays to create data frames. Each list will be a row, instead of a column, and you will need to specify the column name as another argument in `pd.DataFrame()` called `columns`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [\n",
    "    [1, 'apple', -2.],\n",
    "    [3, 'banana', -3.],\n",
    "    [5, 'apple', -5.]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: we need to save this as a variable to use it in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sort the rows in a data frame by the value of a column, we can use the `.sort_values()` method. The argument `by` requires a list with a column name. \n",
    "\n",
    "Again, if you want to use the sorted version in the future, you need to save it as a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = pd.DataFrame(data_list, columns=['a', 'b', 'c'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also sort descending by specifying the `ascending=False` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If desired, multiple column names can be specified, with priority given to those first in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add rows\n",
    "There are multiple ways to add a new row to a data frame. The most straightforward way is to use the `pandas.concat()` function with a new data frame with just one row. \n",
    "\n",
    "We put the the two data frames into a list, and we set `axis=0` to make sure it adds as a row. We will specify `.reset_index(drop=True)` to reset row numbers to account for the new row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = pd.DataFrame({\n",
    "    'a': [2],\n",
    "    'b': ['banana'],\n",
    "    'c': [-1.]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use this approach to add multiple rows, as well, by having the new data frame consist of multiple rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rows = pd.DataFrame({\n",
    "    'a': [6, 5],\n",
    "    'b': ['banana', 'orange'],\n",
    "    'c': [-4., -9.]\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join data frames\n",
    "A critical tool in data wrangling is combining data frames that share common values, columns, or identifiers.\n",
    "\n",
    "Let's important two new .csv files and join them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_df = pd.read_csv(\"https://raw.githubusercontent.com/DeisData/python/master/data/surveys.csv\", keep_default_na=False, na_values=[\"\"])\n",
    "species_df = pd.read_csv(\"https://raw.githubusercontent.com/DeisData/python/master/data/species.csv\", keep_default_na=False, na_values=[\"\"])\n",
    "\n",
    "print(surveys_df.head())\n",
    "print(species_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shared column between these data frames is `species_id`, so this is the column we will want to join around."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inner Join\n",
    "The pandas function for performing joins is called `merge()` and an Inner join is the default option.\n",
    "\n",
    "Inner joins take all rows from both data frames that share values from an identifier column. In our case, this means that our joined data frame will only include rows with species identifiers present in `species_df` and `surveys_df`.\n",
    "\n",
    "<img src=\"../images/innerjoin.png\" alt=\"inner join\" width=250px>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result `merged_inner` data frame contains all of the columns from `surveys_df` (`record_id`, `month`, `day`, etc.) as well as all the columns from `species_df` (`species_id`, `genus`, `species`, and `taxa`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Left join\n",
    "\n",
    "What if we want to add information from `species_df` to `surveys_df`without losing any of the information from `surveys_df`? In this case, we use a different type of join called a left join, where we keep all rows from the data frame we call left (in our case `surveys_df`) and only take rows from the right data frame (`species_df`) with species IDs in `surveys_df`.\n",
    "\n",
    "<img src=\"../images/leftjoin.png\" alt=\"left join\" width=250px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A left join is performed in pandas by calling the same `merge()` function used for inner join, but using the `how='left'` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export data frame as .csv\n",
    "\n",
    "If you have made modifications to a data set in Python and want to export that to a new .csv, you can easily do that with the `.to_csv()` method that all pandas data frames have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Putting it together\n",
    "\n",
    "Create two data frames called `A` and `B` with at least 3 columns and 4 rows. Make one column in both `A` and `B` an identifier column, with at least one ID present in both data frames. Use a left join with `A` as the left data frame, and call the new data frame `C`. Display the data frame, and export it as a .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- [NumPy docs](https://numpy.org/doc/stable/index.html)\n",
    "- [NumPy getting started](https://numpy.org/doc/stable/user/quickstart.html)\n",
    "- [Random samples with NumPy](https://numpy.org/doc/stable/reference/random/index.html)\n",
    "- [Pandas docs](https://pandas.pydata.org/docs/)\n",
    "- [Pandas getting started](https://pandas.pydata.org/docs/getting_started/index.html#getting-started)\n",
    "- [Pandas cheatsheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)\n",
    "- [PySpark for big data](https://spark.apache.org/docs/latest/api/python/)\n",
    "\n",
    "This lesson is adapted from \n",
    "[Software Carpentry](http://swcarpentry.github.io/python-novice-gapminder/design/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('workshop')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e5670abb08844f1af3bbc7bb9ef8e3b4ef400ad7b254432ac9e559b82ca9501"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
